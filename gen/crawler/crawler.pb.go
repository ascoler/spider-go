// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.11
// 	protoc        v6.33.1
// source: crawler.proto

package crawler

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	timestamppb "google.golang.org/protobuf/types/known/timestamppb"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

type StartCrawlingRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	SeedUrls      []string               `protobuf:"bytes,1,rep,name=seed_urls,json=seedUrls,proto3" json:"seed_urls,omitempty"`
	Config        *Config                `protobuf:"bytes,2,opt,name=config,proto3" json:"config,omitempty"`
	MaxPages      int32                  `protobuf:"varint,3,opt,name=max_pages,json=maxPages,proto3" json:"max_pages,omitempty"` // Добавлено для переопределения config.max_pages
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StartCrawlingRequest) Reset() {
	*x = StartCrawlingRequest{}
	mi := &file_crawler_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StartCrawlingRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StartCrawlingRequest) ProtoMessage() {}

func (x *StartCrawlingRequest) ProtoReflect() protoreflect.Message {
	mi := &file_crawler_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StartCrawlingRequest.ProtoReflect.Descriptor instead.
func (*StartCrawlingRequest) Descriptor() ([]byte, []int) {
	return file_crawler_proto_rawDescGZIP(), []int{0}
}

func (x *StartCrawlingRequest) GetSeedUrls() []string {
	if x != nil {
		return x.SeedUrls
	}
	return nil
}

func (x *StartCrawlingRequest) GetConfig() *Config {
	if x != nil {
		return x.Config
	}
	return nil
}

func (x *StartCrawlingRequest) GetMaxPages() int32 {
	if x != nil {
		return x.MaxPages
	}
	return 0
}

type StartCrawlingResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	JobId         string                 `protobuf:"bytes,1,opt,name=job_id,json=jobId,proto3" json:"job_id,omitempty"`
	Status        string                 `protobuf:"bytes,2,opt,name=status,proto3" json:"status,omitempty"`
	StartedAt     *timestamppb.Timestamp `protobuf:"bytes,3,opt,name=started_at,json=startedAt,proto3" json:"started_at,omitempty"`
	Content       []string               `protobuf:"bytes,4,rep,name=content,proto3" json:"content,omitempty"` // Добавлено для возврата контента
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StartCrawlingResponse) Reset() {
	*x = StartCrawlingResponse{}
	mi := &file_crawler_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StartCrawlingResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StartCrawlingResponse) ProtoMessage() {}

func (x *StartCrawlingResponse) ProtoReflect() protoreflect.Message {
	mi := &file_crawler_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StartCrawlingResponse.ProtoReflect.Descriptor instead.
func (*StartCrawlingResponse) Descriptor() ([]byte, []int) {
	return file_crawler_proto_rawDescGZIP(), []int{1}
}

func (x *StartCrawlingResponse) GetJobId() string {
	if x != nil {
		return x.JobId
	}
	return ""
}

func (x *StartCrawlingResponse) GetStatus() string {
	if x != nil {
		return x.Status
	}
	return ""
}

func (x *StartCrawlingResponse) GetStartedAt() *timestamppb.Timestamp {
	if x != nil {
		return x.StartedAt
	}
	return nil
}

func (x *StartCrawlingResponse) GetContent() []string {
	if x != nil {
		return x.Content
	}
	return nil
}

type CrawlingStatusRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	JobId         string                 `protobuf:"bytes,1,opt,name=job_id,json=jobId,proto3" json:"job_id,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CrawlingStatusRequest) Reset() {
	*x = CrawlingStatusRequest{}
	mi := &file_crawler_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CrawlingStatusRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CrawlingStatusRequest) ProtoMessage() {}

func (x *CrawlingStatusRequest) ProtoReflect() protoreflect.Message {
	mi := &file_crawler_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CrawlingStatusRequest.ProtoReflect.Descriptor instead.
func (*CrawlingStatusRequest) Descriptor() ([]byte, []int) {
	return file_crawler_proto_rawDescGZIP(), []int{2}
}

func (x *CrawlingStatusRequest) GetJobId() string {
	if x != nil {
		return x.JobId
	}
	return ""
}

type CrawlingStatusResponse struct {
	state           protoimpl.MessageState `protogen:"open.v1"`
	JobId           string                 `protobuf:"bytes,1,opt,name=job_id,json=jobId,proto3" json:"job_id,omitempty"`
	Status          string                 `protobuf:"bytes,2,opt,name=status,proto3" json:"status,omitempty"`
	PagesCrawled    int32                  `protobuf:"varint,3,opt,name=pages_crawled,json=pagesCrawled,proto3" json:"pages_crawled,omitempty"`
	LinksDiscovered int32                  `protobuf:"varint,4,opt,name=links_discovered,json=linksDiscovered,proto3" json:"links_discovered,omitempty"`
	StartedAt       *timestamppb.Timestamp `protobuf:"bytes,5,opt,name=started_at,json=startedAt,proto3" json:"started_at,omitempty"`
	LastUpdated     *timestamppb.Timestamp `protobuf:"bytes,6,opt,name=last_updated,json=lastUpdated,proto3" json:"last_updated,omitempty"`
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *CrawlingStatusResponse) Reset() {
	*x = CrawlingStatusResponse{}
	mi := &file_crawler_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CrawlingStatusResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CrawlingStatusResponse) ProtoMessage() {}

func (x *CrawlingStatusResponse) ProtoReflect() protoreflect.Message {
	mi := &file_crawler_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CrawlingStatusResponse.ProtoReflect.Descriptor instead.
func (*CrawlingStatusResponse) Descriptor() ([]byte, []int) {
	return file_crawler_proto_rawDescGZIP(), []int{3}
}

func (x *CrawlingStatusResponse) GetJobId() string {
	if x != nil {
		return x.JobId
	}
	return ""
}

func (x *CrawlingStatusResponse) GetStatus() string {
	if x != nil {
		return x.Status
	}
	return ""
}

func (x *CrawlingStatusResponse) GetPagesCrawled() int32 {
	if x != nil {
		return x.PagesCrawled
	}
	return 0
}

func (x *CrawlingStatusResponse) GetLinksDiscovered() int32 {
	if x != nil {
		return x.LinksDiscovered
	}
	return 0
}

func (x *CrawlingStatusResponse) GetStartedAt() *timestamppb.Timestamp {
	if x != nil {
		return x.StartedAt
	}
	return nil
}

func (x *CrawlingStatusResponse) GetLastUpdated() *timestamppb.Timestamp {
	if x != nil {
		return x.LastUpdated
	}
	return nil
}

type StopCrawlingRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	JobId         string                 `protobuf:"bytes,1,opt,name=job_id,json=jobId,proto3" json:"job_id,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StopCrawlingRequest) Reset() {
	*x = StopCrawlingRequest{}
	mi := &file_crawler_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StopCrawlingRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StopCrawlingRequest) ProtoMessage() {}

func (x *StopCrawlingRequest) ProtoReflect() protoreflect.Message {
	mi := &file_crawler_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StopCrawlingRequest.ProtoReflect.Descriptor instead.
func (*StopCrawlingRequest) Descriptor() ([]byte, []int) {
	return file_crawler_proto_rawDescGZIP(), []int{4}
}

func (x *StopCrawlingRequest) GetJobId() string {
	if x != nil {
		return x.JobId
	}
	return ""
}

type StopCrawlingResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	JobId         string                 `protobuf:"bytes,1,opt,name=job_id,json=jobId,proto3" json:"job_id,omitempty"`
	Status        string                 `protobuf:"bytes,2,opt,name=status,proto3" json:"status,omitempty"`
	StoppedAt     *timestamppb.Timestamp `protobuf:"bytes,3,opt,name=stopped_at,json=stoppedAt,proto3" json:"stopped_at,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StopCrawlingResponse) Reset() {
	*x = StopCrawlingResponse{}
	mi := &file_crawler_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StopCrawlingResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StopCrawlingResponse) ProtoMessage() {}

func (x *StopCrawlingResponse) ProtoReflect() protoreflect.Message {
	mi := &file_crawler_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StopCrawlingResponse.ProtoReflect.Descriptor instead.
func (*StopCrawlingResponse) Descriptor() ([]byte, []int) {
	return file_crawler_proto_rawDescGZIP(), []int{5}
}

func (x *StopCrawlingResponse) GetJobId() string {
	if x != nil {
		return x.JobId
	}
	return ""
}

func (x *StopCrawlingResponse) GetStatus() string {
	if x != nil {
		return x.Status
	}
	return ""
}

func (x *StopCrawlingResponse) GetStoppedAt() *timestamppb.Timestamp {
	if x != nil {
		return x.StoppedAt
	}
	return nil
}

type GetLinksRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	JobId         string                 `protobuf:"bytes,1,opt,name=job_id,json=jobId,proto3" json:"job_id,omitempty"`
	Limit         int32                  `protobuf:"varint,2,opt,name=limit,proto3" json:"limit,omitempty"`
	Offset        int32                  `protobuf:"varint,3,opt,name=offset,proto3" json:"offset,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetLinksRequest) Reset() {
	*x = GetLinksRequest{}
	mi := &file_crawler_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetLinksRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetLinksRequest) ProtoMessage() {}

func (x *GetLinksRequest) ProtoReflect() protoreflect.Message {
	mi := &file_crawler_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetLinksRequest.ProtoReflect.Descriptor instead.
func (*GetLinksRequest) Descriptor() ([]byte, []int) {
	return file_crawler_proto_rawDescGZIP(), []int{6}
}

func (x *GetLinksRequest) GetJobId() string {
	if x != nil {
		return x.JobId
	}
	return ""
}

func (x *GetLinksRequest) GetLimit() int32 {
	if x != nil {
		return x.Limit
	}
	return 0
}

func (x *GetLinksRequest) GetOffset() int32 {
	if x != nil {
		return x.Offset
	}
	return 0
}

type GetLinksResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Links         []*Link                `protobuf:"bytes,1,rep,name=links,proto3" json:"links,omitempty"`
	TotalCount    int32                  `protobuf:"varint,2,opt,name=total_count,json=totalCount,proto3" json:"total_count,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetLinksResponse) Reset() {
	*x = GetLinksResponse{}
	mi := &file_crawler_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetLinksResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetLinksResponse) ProtoMessage() {}

func (x *GetLinksResponse) ProtoReflect() protoreflect.Message {
	mi := &file_crawler_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetLinksResponse.ProtoReflect.Descriptor instead.
func (*GetLinksResponse) Descriptor() ([]byte, []int) {
	return file_crawler_proto_rawDescGZIP(), []int{7}
}

func (x *GetLinksResponse) GetLinks() []*Link {
	if x != nil {
		return x.Links
	}
	return nil
}

func (x *GetLinksResponse) GetTotalCount() int32 {
	if x != nil {
		return x.TotalCount
	}
	return 0
}

type Link struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Url           string                 `protobuf:"bytes,1,opt,name=url,proto3" json:"url,omitempty"`
	AnchorText    string                 `protobuf:"bytes,2,opt,name=anchor_text,json=anchorText,proto3" json:"anchor_text,omitempty"`
	Domain        string                 `protobuf:"bytes,3,opt,name=domain,proto3" json:"domain,omitempty"`
	DiscoveredAt  *timestamppb.Timestamp `protobuf:"bytes,4,opt,name=discovered_at,json=discoveredAt,proto3" json:"discovered_at,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Link) Reset() {
	*x = Link{}
	mi := &file_crawler_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Link) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Link) ProtoMessage() {}

func (x *Link) ProtoReflect() protoreflect.Message {
	mi := &file_crawler_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Link.ProtoReflect.Descriptor instead.
func (*Link) Descriptor() ([]byte, []int) {
	return file_crawler_proto_rawDescGZIP(), []int{8}
}

func (x *Link) GetUrl() string {
	if x != nil {
		return x.Url
	}
	return ""
}

func (x *Link) GetAnchorText() string {
	if x != nil {
		return x.AnchorText
	}
	return ""
}

func (x *Link) GetDomain() string {
	if x != nil {
		return x.Domain
	}
	return ""
}

func (x *Link) GetDiscoveredAt() *timestamppb.Timestamp {
	if x != nil {
		return x.DiscoveredAt
	}
	return nil
}

type Config struct {
	state          protoimpl.MessageState `protogen:"open.v1"`
	MaxDepth       int32                  `protobuf:"varint,1,opt,name=max_depth,json=maxDepth,proto3" json:"max_depth,omitempty"`
	MaxPages       int32                  `protobuf:"varint,2,opt,name=max_pages,json=maxPages,proto3" json:"max_pages,omitempty"`
	WorkerPoolSize int32                  `protobuf:"varint,3,opt,name=worker_pool_size,json=workerPoolSize,proto3" json:"worker_pool_size,omitempty"`
	RequestTimeout int32                  `protobuf:"varint,4,opt,name=request_timeout,json=requestTimeout,proto3" json:"request_timeout,omitempty"`
	MaxRetries     int32                  `protobuf:"varint,5,opt,name=max_retries,json=maxRetries,proto3" json:"max_retries,omitempty"`
	RetryDelay     int32                  `protobuf:"varint,6,opt,name=retry_delay,json=retryDelay,proto3" json:"retry_delay,omitempty"`
	RateLimitDelay int32                  `protobuf:"varint,7,opt,name=rate_limit_delay,json=rateLimitDelay,proto3" json:"rate_limit_delay,omitempty"`
	StorageType    string                 `protobuf:"bytes,8,opt,name=storage_type,json=storageType,proto3" json:"storage_type,omitempty"`
	LogLevel       string                 `protobuf:"bytes,9,opt,name=log_level,json=logLevel,proto3" json:"log_level,omitempty"`
	OutputFile     string                 `protobuf:"bytes,10,opt,name=output_file,json=outputFile,proto3" json:"output_file,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *Config) Reset() {
	*x = Config{}
	mi := &file_crawler_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Config) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Config) ProtoMessage() {}

func (x *Config) ProtoReflect() protoreflect.Message {
	mi := &file_crawler_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Config.ProtoReflect.Descriptor instead.
func (*Config) Descriptor() ([]byte, []int) {
	return file_crawler_proto_rawDescGZIP(), []int{9}
}

func (x *Config) GetMaxDepth() int32 {
	if x != nil {
		return x.MaxDepth
	}
	return 0
}

func (x *Config) GetMaxPages() int32 {
	if x != nil {
		return x.MaxPages
	}
	return 0
}

func (x *Config) GetWorkerPoolSize() int32 {
	if x != nil {
		return x.WorkerPoolSize
	}
	return 0
}

func (x *Config) GetRequestTimeout() int32 {
	if x != nil {
		return x.RequestTimeout
	}
	return 0
}

func (x *Config) GetMaxRetries() int32 {
	if x != nil {
		return x.MaxRetries
	}
	return 0
}

func (x *Config) GetRetryDelay() int32 {
	if x != nil {
		return x.RetryDelay
	}
	return 0
}

func (x *Config) GetRateLimitDelay() int32 {
	if x != nil {
		return x.RateLimitDelay
	}
	return 0
}

func (x *Config) GetStorageType() string {
	if x != nil {
		return x.StorageType
	}
	return ""
}

func (x *Config) GetLogLevel() string {
	if x != nil {
		return x.LogLevel
	}
	return ""
}

func (x *Config) GetOutputFile() string {
	if x != nil {
		return x.OutputFile
	}
	return ""
}

var File_crawler_proto protoreflect.FileDescriptor

const file_crawler_proto_rawDesc = "" +
	"\n" +
	"\rcrawler.proto\x12\acrawler\x1a\x1fgoogle/protobuf/timestamp.proto\"y\n" +
	"\x14StartCrawlingRequest\x12\x1b\n" +
	"\tseed_urls\x18\x01 \x03(\tR\bseedUrls\x12'\n" +
	"\x06config\x18\x02 \x01(\v2\x0f.crawler.ConfigR\x06config\x12\x1b\n" +
	"\tmax_pages\x18\x03 \x01(\x05R\bmaxPages\"\x9b\x01\n" +
	"\x15StartCrawlingResponse\x12\x15\n" +
	"\x06job_id\x18\x01 \x01(\tR\x05jobId\x12\x16\n" +
	"\x06status\x18\x02 \x01(\tR\x06status\x129\n" +
	"\n" +
	"started_at\x18\x03 \x01(\v2\x1a.google.protobuf.TimestampR\tstartedAt\x12\x18\n" +
	"\acontent\x18\x04 \x03(\tR\acontent\".\n" +
	"\x15CrawlingStatusRequest\x12\x15\n" +
	"\x06job_id\x18\x01 \x01(\tR\x05jobId\"\x91\x02\n" +
	"\x16CrawlingStatusResponse\x12\x15\n" +
	"\x06job_id\x18\x01 \x01(\tR\x05jobId\x12\x16\n" +
	"\x06status\x18\x02 \x01(\tR\x06status\x12#\n" +
	"\rpages_crawled\x18\x03 \x01(\x05R\fpagesCrawled\x12)\n" +
	"\x10links_discovered\x18\x04 \x01(\x05R\x0flinksDiscovered\x129\n" +
	"\n" +
	"started_at\x18\x05 \x01(\v2\x1a.google.protobuf.TimestampR\tstartedAt\x12=\n" +
	"\flast_updated\x18\x06 \x01(\v2\x1a.google.protobuf.TimestampR\vlastUpdated\",\n" +
	"\x13StopCrawlingRequest\x12\x15\n" +
	"\x06job_id\x18\x01 \x01(\tR\x05jobId\"\x80\x01\n" +
	"\x14StopCrawlingResponse\x12\x15\n" +
	"\x06job_id\x18\x01 \x01(\tR\x05jobId\x12\x16\n" +
	"\x06status\x18\x02 \x01(\tR\x06status\x129\n" +
	"\n" +
	"stopped_at\x18\x03 \x01(\v2\x1a.google.protobuf.TimestampR\tstoppedAt\"V\n" +
	"\x0fGetLinksRequest\x12\x15\n" +
	"\x06job_id\x18\x01 \x01(\tR\x05jobId\x12\x14\n" +
	"\x05limit\x18\x02 \x01(\x05R\x05limit\x12\x16\n" +
	"\x06offset\x18\x03 \x01(\x05R\x06offset\"X\n" +
	"\x10GetLinksResponse\x12#\n" +
	"\x05links\x18\x01 \x03(\v2\r.crawler.LinkR\x05links\x12\x1f\n" +
	"\vtotal_count\x18\x02 \x01(\x05R\n" +
	"totalCount\"\x92\x01\n" +
	"\x04Link\x12\x10\n" +
	"\x03url\x18\x01 \x01(\tR\x03url\x12\x1f\n" +
	"\vanchor_text\x18\x02 \x01(\tR\n" +
	"anchorText\x12\x16\n" +
	"\x06domain\x18\x03 \x01(\tR\x06domain\x12?\n" +
	"\rdiscovered_at\x18\x04 \x01(\v2\x1a.google.protobuf.TimestampR\fdiscoveredAt\"\xe2\x02\n" +
	"\x06Config\x12\x1b\n" +
	"\tmax_depth\x18\x01 \x01(\x05R\bmaxDepth\x12\x1b\n" +
	"\tmax_pages\x18\x02 \x01(\x05R\bmaxPages\x12(\n" +
	"\x10worker_pool_size\x18\x03 \x01(\x05R\x0eworkerPoolSize\x12'\n" +
	"\x0frequest_timeout\x18\x04 \x01(\x05R\x0erequestTimeout\x12\x1f\n" +
	"\vmax_retries\x18\x05 \x01(\x05R\n" +
	"maxRetries\x12\x1f\n" +
	"\vretry_delay\x18\x06 \x01(\x05R\n" +
	"retryDelay\x12(\n" +
	"\x10rate_limit_delay\x18\a \x01(\x05R\x0erateLimitDelay\x12!\n" +
	"\fstorage_type\x18\b \x01(\tR\vstorageType\x12\x1b\n" +
	"\tlog_level\x18\t \x01(\tR\blogLevel\x12\x1f\n" +
	"\voutput_file\x18\n" +
	" \x01(\tR\n" +
	"outputFile2\xce\x02\n" +
	"\x0eCrawlerService\x12N\n" +
	"\rStartCrawling\x12\x1d.crawler.StartCrawlingRequest\x1a\x1e.crawler.StartCrawlingResponse\x12T\n" +
	"\x11GetCrawlingStatus\x12\x1e.crawler.CrawlingStatusRequest\x1a\x1f.crawler.CrawlingStatusResponse\x12K\n" +
	"\fStopCrawling\x12\x1c.crawler.StopCrawlingRequest\x1a\x1d.crawler.StopCrawlingResponse\x12I\n" +
	"\x12GetDiscoveredLinks\x12\x18.crawler.GetLinksRequest\x1a\x19.crawler.GetLinksResponseB\x1fZ\x1dspider-go/gen/crawler;crawlerb\x06proto3"

var (
	file_crawler_proto_rawDescOnce sync.Once
	file_crawler_proto_rawDescData []byte
)

func file_crawler_proto_rawDescGZIP() []byte {
	file_crawler_proto_rawDescOnce.Do(func() {
		file_crawler_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_crawler_proto_rawDesc), len(file_crawler_proto_rawDesc)))
	})
	return file_crawler_proto_rawDescData
}

var file_crawler_proto_msgTypes = make([]protoimpl.MessageInfo, 10)
var file_crawler_proto_goTypes = []any{
	(*StartCrawlingRequest)(nil),   // 0: crawler.StartCrawlingRequest
	(*StartCrawlingResponse)(nil),  // 1: crawler.StartCrawlingResponse
	(*CrawlingStatusRequest)(nil),  // 2: crawler.CrawlingStatusRequest
	(*CrawlingStatusResponse)(nil), // 3: crawler.CrawlingStatusResponse
	(*StopCrawlingRequest)(nil),    // 4: crawler.StopCrawlingRequest
	(*StopCrawlingResponse)(nil),   // 5: crawler.StopCrawlingResponse
	(*GetLinksRequest)(nil),        // 6: crawler.GetLinksRequest
	(*GetLinksResponse)(nil),       // 7: crawler.GetLinksResponse
	(*Link)(nil),                   // 8: crawler.Link
	(*Config)(nil),                 // 9: crawler.Config
	(*timestamppb.Timestamp)(nil),  // 10: google.protobuf.Timestamp
}
var file_crawler_proto_depIdxs = []int32{
	9,  // 0: crawler.StartCrawlingRequest.config:type_name -> crawler.Config
	10, // 1: crawler.StartCrawlingResponse.started_at:type_name -> google.protobuf.Timestamp
	10, // 2: crawler.CrawlingStatusResponse.started_at:type_name -> google.protobuf.Timestamp
	10, // 3: crawler.CrawlingStatusResponse.last_updated:type_name -> google.protobuf.Timestamp
	10, // 4: crawler.StopCrawlingResponse.stopped_at:type_name -> google.protobuf.Timestamp
	8,  // 5: crawler.GetLinksResponse.links:type_name -> crawler.Link
	10, // 6: crawler.Link.discovered_at:type_name -> google.protobuf.Timestamp
	0,  // 7: crawler.CrawlerService.StartCrawling:input_type -> crawler.StartCrawlingRequest
	2,  // 8: crawler.CrawlerService.GetCrawlingStatus:input_type -> crawler.CrawlingStatusRequest
	4,  // 9: crawler.CrawlerService.StopCrawling:input_type -> crawler.StopCrawlingRequest
	6,  // 10: crawler.CrawlerService.GetDiscoveredLinks:input_type -> crawler.GetLinksRequest
	1,  // 11: crawler.CrawlerService.StartCrawling:output_type -> crawler.StartCrawlingResponse
	3,  // 12: crawler.CrawlerService.GetCrawlingStatus:output_type -> crawler.CrawlingStatusResponse
	5,  // 13: crawler.CrawlerService.StopCrawling:output_type -> crawler.StopCrawlingResponse
	7,  // 14: crawler.CrawlerService.GetDiscoveredLinks:output_type -> crawler.GetLinksResponse
	11, // [11:15] is the sub-list for method output_type
	7,  // [7:11] is the sub-list for method input_type
	7,  // [7:7] is the sub-list for extension type_name
	7,  // [7:7] is the sub-list for extension extendee
	0,  // [0:7] is the sub-list for field type_name
}

func init() { file_crawler_proto_init() }
func file_crawler_proto_init() {
	if File_crawler_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_crawler_proto_rawDesc), len(file_crawler_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   10,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_crawler_proto_goTypes,
		DependencyIndexes: file_crawler_proto_depIdxs,
		MessageInfos:      file_crawler_proto_msgTypes,
	}.Build()
	File_crawler_proto = out.File
	file_crawler_proto_goTypes = nil
	file_crawler_proto_depIdxs = nil
}
